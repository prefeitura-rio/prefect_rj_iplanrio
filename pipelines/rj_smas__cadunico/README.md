# Pipeline Cad√önico - Sistema de Prote√ß√£o Social

Pipeline automatizada para ingest√£o de dados do Cad√önico (Cadastro √önico para Programas Sociais) e gera√ß√£o de modelos DBT para materializa√ß√£o no BigQuery.

## üìã Vis√£o Geral

Esta pipeline processa dados do Cad√önico em duas etapas principais:
1. **Dump de Dados**: Ingest√£o otimizada de arquivos raw para staging
2. **Gera√ß√£o DBT**: Cria√ß√£o autom√°tica de modelos DBT e materializa√ß√£o

O sistema utiliza layouts versionados para garantir compatibilidade entre diferentes vers√µes dos dados, valida√ß√£o autom√°tica de dicion√°rios e integra√ß√£o Git para versionamento de c√≥digo.

## üîÑ Fluxo da Pipeline

```mermaid
flowchart TD
    A[üì• In√≠cio da Pipeline] --> B{Verificar Parti√ß√µes Existentes}
    B --> C[üìÇ Listar Arquivos Raw]
    C --> D{H√° Novos Arquivos?}

    D -->|Sim| E[üîÑ DUMP DE DADOS]
    D -->|N√£o| F[‚è≠Ô∏è Pular Dump]

    E --> E1[üì• Ingerir Arquivos]
    E1 --> E2[üîÑ Processar Dados]
    E2 --> E3[‚¨ÜÔ∏è Upload para Staging]
    E3 --> G[üèóÔ∏è GERA√á√ÉO DBT]
    F --> G

    G --> G1[üì¶ Download Reposit√≥rio Git]
    G1 --> G2[üîç Verificar Layouts]
    G2 --> G3[‚úÖ Validar Dicion√°rio]
    G3 --> G4[üèóÔ∏è Gerar Modelos DBT]
    G4 --> G5[üåø Criar Branch]
    G5 --> G6[‚¨ÜÔ∏è Push para GitHub]
    G6 --> G7[üöÄ Executar DBT]
    G7 --> H[‚úÖ Pipeline Conclu√≠da]

    style A fill:#e1f5fe
    style E fill:#fff3e0
    style G fill:#e8f5e8
    style H fill:#c8e6c9
```

---

## üîß Grupo 1: Dump de Dados

O processo de dump √© respons√°vel por ingerir e processar arquivos raw do Cad√önico de forma otimizada e incremental.

### üéØ Objetivo
- Verificar parti√ß√µes j√° processadas
- Identificar novos arquivos para ingest√£o
- Processar e fazer upload para √°rea de staging

### üìä Tasks do Dump

#### `get_existing_partitions_task`
**Arquivo**: `tasks.py:26`
**Fun√ß√£o**: Lista parti√ß√µes j√° processadas na √°rea de staging
```python
def get_existing_partitions_task(prefix: str, bucket_name: str, dataset_id: str, table_id: str) -> List[str]
```

#### `get_files_to_ingest_task`
**Arquivo**: `tasks.py:31`
**Fun√ß√£o**: Identifica arquivos novos comparando raw vs staging
```python
def get_files_to_ingest_task(prefix: str, partitions: List[str], bucket_name: str) -> List[str]
```

#### `need_to_ingest_task`
**Arquivo**: `tasks.py:36`
**Fun√ß√£o**: Determina se h√° arquivos para processar
```python
def need_to_ingest_task(files_to_ingest: list) -> bool
```

#### `ingest_files_task`
**Arquivo**: `tasks.py:41`
**Fun√ß√£o**: Processa arquivos de forma ass√≠ncrona com controle de concorr√™ncia
```python
def ingest_files_task(files_to_ingest: List[str], bucket_name: str, dataset_id: str, table_id: str, max_concurrent: int = 3) -> None
```

### üîß Utils do Dump

#### `utils_dump.py`
**Fun√ß√µes principais**:
- `get_existing_partitions()`: Lista parti√ß√µes em staging
- `get_files_to_ingest()`: Compara raw vs staging
- `ingest_files()`: Processamento ass√≠ncrono de arquivos
- `need_to_ingest()`: Valida√ß√£o de necessidade de ingest√£o

**Caracter√≠sticas**:
- ‚úÖ Processamento incremental (s√≥ novos arquivos)
- ‚úÖ Controle de concorr√™ncia configur√°vel
- ‚úÖ Upload direto para BigQuery
- ‚úÖ Logs detalhados de progresso

---

## üèóÔ∏è Grupo 2: Gera√ß√£o DBT e Materializa√ß√£o

O processo de gera√ß√£o DBT cria automaticamente modelos compat√≠veis com diferentes vers√µes de layout e os materializa no BigQuery.

### üéØ Objetivo
- Sincronizar layouts do storage com staging
- Validar dicion√°rio de colunas
- Gerar modelos DBT automaticamente
- Fazer push para reposit√≥rio Git
- Executar materializa√ß√£o no BigQuery

### üìä Tasks da Gera√ß√£o DBT

#### `download_repository_task`
**Arquivo**: `tasks.py:58`
**Fun√ß√£o**: Baixa reposit√≥rio Git para gera√ß√£o de modelos
```python
def download_repository_task(git_repository_path: str, branch: str = "master") -> str
```

#### `update_layout_from_storage_and_create_versions_dbt_models_task`
**Arquivo**: `tasks.py:64`
**Fun√ß√£o**: N√∫cleo da pipeline - sincroniza layouts e gera modelos
```python
def update_layout_from_storage_and_create_versions_dbt_models_task(
    dataset_id: str = "brutos_cadunico",
    layout_table_id: str = "layout",
    # ... outros par√¢metros
)
```

#### `push_models_to_branch_task`
**Arquivo**: `tasks.py:87`
**Fun√ß√£o**: Faz commit e push dos modelos gerados
```python
def push_models_to_branch_task(
    repository_path: str,
    github_token: Optional[str] = None,
    commit_message: str = "feat: update CadUnico models"
) -> bool
```

#### `execute_dbt_task`
**Arquivo**: `tasks.py:107`
**Fun√ß√£o**: Executa DBT run para materializa√ß√£o
```python
def execute_dbt_task(target: str = "prod", select: str = "--select raw.smas.protecao_social_cadunico")
```

### üîß Utils da Gera√ß√£o DBT

#### `utils_layout.py` - Processamento de Layouts
**Fun√ß√µes principais**:

##### Valida√ß√£o e Sincroniza√ß√£o
- `get_layout_table_from_staging()` (linha 289): Valida dicion√°rio de colunas
- `download_files_from_storage_raw()` (linha 222): Baixa layouts novos
- `parse_xlsx_files_and_save_partition()` (linha 167): Processa arquivos Excel

##### Gera√ß√£o de Modelos
- `create_cadunico_dbt_consolidated_models()` (linha 501): Gera modelos DBT
- `parse_columns_version_control()` (linha 413): Controle de vers√µes cross-layout
- `columns_version_control_diff()` (linha 376): An√°lise de diferen√ßas entre vers√µes

**Caracter√≠sticas do Layout**:
- ‚úÖ **Valida√ß√£o autom√°tica**: Verifica se todas as colunas t√™m dicion√°rio
- ‚úÖ **Controle de vers√µes**: Compatibilidade entre vers√µes diferentes
- ‚úÖ **Gera√ß√£o autom√°tica**: Modelos DBT com transforma√ß√µes complexas
- ‚úÖ **Tratamento de tipos**: DATE, INT64, FLOAT64 com valida√ß√µes

#### `utils_dbt.py` - Integra√ß√£o Git e DBT
**Fun√ß√µes principais**:

##### Git Operations
- `download_repository()` (linha 27): Clone de reposit√≥rio com branch espec√≠fica
- `push_models_to_branch()` (linha 74): Push com autentica√ß√£o via token
- `get_github_token()` (linha 11): Valida√ß√£o de token de ambiente

##### DBT Execution
- `execute_dbt()` (linha 190): Execu√ß√£o com PrefectDbtRunner
  - Instala depend√™ncias automaticamente
  - Suporta m√∫ltiplos comandos (run, test, build)
  - Tratamento gracioso de erros

**Caracter√≠sticas do DBT**:
- ‚úÖ **Autentica√ß√£o segura**: GitHub token via vari√°vel de ambiente
- ‚úÖ **Commits descritivos**: Mensagens autom√°ticas com contexto
- ‚úÖ **Execu√ß√£o robusta**: deps + run com tratamento de erros
- ‚úÖ **Flexibilidade**: targets e sele√ß√µes configur√°veis

---

## ‚öôÔ∏è Configura√ß√£o e Uso

### Vari√°veis de Ambiente Necess√°rias
```bash
GITHUB_TOKEN=ghp_xxxxxxxxxxxxx  # Token com permiss√µes repo, contents:write
```

### Par√¢metros do Flow
```python
@flow
def rj_smas__cadunico(
    raw_bucket: str = "rj-smas",
    raw_prefix_area: str = "raw/protecao_social_cadunico/registro_familia",
    staging_bucket: str = "rj-iplanrio",
    dataset_id: str = "brutos_cadunico",
    max_concurrent: int = 3,
    force_create_models: bool = False,
    git_repository_path: str = "https://github.com/prefeitura-rio/queries-rj-iplanrio",
    branch: str = "cadunico",
    dbt_target: str = "prod",
    dbt_select: str = "--select raw.smas.protecao_social_cadunico"
)
```

### Estrutura de Arquivos Gerados
```
dbt_repository/
‚îî‚îÄ‚îÄ models/raw/smas/protecao_social_cadunico/
    ‚îú‚îÄ‚îÄ raw_protecao_social_cadunico__controle.sql
    ‚îú‚îÄ‚îÄ raw_protecao_social_cadunico__controle.yml
    ‚îú‚îÄ‚îÄ raw_protecao_social_cadunico__familia.sql
    ‚îú‚îÄ‚îÄ raw_protecao_social_cadunico__familia.yml
    ‚îî‚îÄ‚îÄ ... (outros modelos)
```

---

## üîç Caracter√≠sticas T√©cnicas

### Otimiza√ß√µes
- **Processamento incremental**: S√≥ processa dados novos
- **Concorr√™ncia controlada**: Upload paralelo com limite configur√°vel
- **Valida√ß√£o pr√©via**: Verifica dicion√°rios antes da gera√ß√£o
- **Cache inteligente**: Reutiliza layouts j√° processados

### Tratamento de Erros
- **Valida√ß√£o de dicion√°rio**: Para pipeline se colunas faltam
- **Verifica√ß√£o de vers√µes**: Garante layouts necess√°rios existem
- **Git operations**: Trata falhas de push/clone graciosamente
- **DBT execution**: Logs detalhados para debugging

### Monitoramento
- **Logs estruturados**: Informa√ß√µes detalhadas em cada etapa
- **Compara√ß√£o de vers√µes**: Raw vs staging em tempo real
- **Progresso de arquivos**: Contadores e percentuais
- **URLs de console**: Links diretos para GCS e BigQuery

---

## üìà M√©tricas e Valida√ß√£o

### Durante Execu√ß√£o
- N√∫mero de arquivos processados
- Parti√ß√µes criadas vs existentes
- Modelos DBT gerados
- Status de push para Git
- Resultado da materializa√ß√£o DBT

### Valida√ß√£o de Qualidade
- ‚úÖ Integridade de dados preservada
- ‚úÖ Compatibilidade entre vers√µes de layout
- ‚úÖ Transforma√ß√µes aplicadas corretamente
- ‚úÖ Metadados e descri√ß√µes propagados